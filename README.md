
# **YOLOv5 + DeepSort ç”¨äºç›®æ ‡è·Ÿè¸ªä¸è®¡æ•°**  
ğŸš—ğŸš¶â€â™‚ï¸ **ä½¿ç”¨ YOLOv5 å’Œ DeepSort å®ç°è½¦è¾†ä¸è¡Œäººå®æ—¶è·Ÿè¸ªä¸è®¡æ•°**

[![GitHub stars](https://img.shields.io/github/stars/Sharpiless/Yolov5-deepsort-inference?style=social)](https://github.com/Sharpiless/Yolov5-deepsort-inference)  [![GitHub forks](https://img.shields.io/github/forks/Sharpiless/Yolov5-deepsort-inference?style=social)](https://github.com/Sharpiless/Yolov5-deepsort-inference)  [![License](https://img.shields.io/github/license/Sharpiless/Yolov5-deepsort-inference)](https://github.com/Sharpiless/Yolov5-deepsort-inference/blob/main/LICENSE)

æœ€æ–°ç‰ˆæœ¬ï¼š[https://github.com/Sharpiless/YOLOv11-DeepSort](https://github.com/Sharpiless/YOLOv11-DeepSort)

---

## **ğŸ“Œ é¡¹ç›®ç®€ä»‹**

æœ¬é¡¹ç›®å°† **YOLOv5** ä¸ **DeepSort** ç›¸ç»“åˆï¼Œå®ç°äº†å¯¹ç›®æ ‡çš„å®æ—¶è·Ÿè¸ªä¸è®¡æ•°ã€‚æä¾›äº†ä¸€ä¸ªå°è£…çš„ `Detector` ç±»ï¼Œæ–¹ä¾¿å°†æ­¤åŠŸèƒ½åµŒå…¥åˆ°è‡ªå®šä¹‰é¡¹ç›®ä¸­ã€‚  

ğŸ”— **é˜…è¯»å®Œæ•´åšå®¢**ï¼š[ã€å°ç™½CVæ•™ç¨‹ã€‘YOLOv5+Deepsortå®ç°è½¦è¾†è¡Œäººçš„æ£€æµ‹ã€è¿½è¸ªå’Œè®¡æ•°](https://blog.csdn.net/weixin_44936889/article/details/112002152)

---

## **ğŸš€ æ ¸å¿ƒåŠŸèƒ½**

- **ç›®æ ‡è·Ÿè¸ª**ï¼šå®æ—¶è·Ÿè¸ªè½¦è¾†ä¸è¡Œäººã€‚
- **è®¡æ•°åŠŸèƒ½**ï¼šè½»æ¾ç»Ÿè®¡è§†é¢‘æµä¸­çš„è½¦è¾†æˆ–è¡Œäººæ•°ã€‚
- **å°è£…å¼æ¥å£**ï¼š`Detector` ç±»å°è£…äº†æ£€æµ‹ä¸è·Ÿè¸ªé€»è¾‘ï¼Œä¾¿äºé›†æˆã€‚
- **é«˜åº¦è‡ªå®šä¹‰**ï¼šæ”¯æŒè®­ç»ƒè‡ªå·±çš„ YOLOv5 æ¨¡å‹å¹¶æ— ç¼æ¥å…¥æ¡†æ¶ã€‚

---

## **ğŸ”§ ä½¿ç”¨è¯´æ˜**

### **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

ç¡®ä¿å®‰è£…äº† `requirements.txt` æ–‡ä»¶ä¸­åˆ—å‡ºçš„æ‰€æœ‰ä¾èµ–ã€‚
### **è¿è¡Œ Demo**
```bash
python demo.py
```
---

## **ğŸ› ï¸ å¼€å‘è¯´æ˜**

### **YOLOv5 æ£€æµ‹å™¨**

```python
class Detector(baseDet):

    def __init__(self):
        super(Detector, self).__init__()
        self.init_model()
        self.build_config()

    def init_model(self):

        self.weights = 'weights/yolov5m.pt'
        self.device = '0' if torch.cuda.is_available() else 'cpu'
        self.device = select_device(self.device)
        model = attempt_load(self.weights, map_location=self.device)
        model.to(self.device).eval()
        model.half()
        # torch.save(model, 'test.pt')
        self.m = model
        self.names = model.module.names if hasattr(
            model, 'module') else model.names

    def preprocess(self, img):

        img0 = img.copy()
        img = letterbox(img, new_shape=self.img_size)[0]
        img = img[:, :, ::-1].transpose(2, 0, 1)
        img = np.ascontiguousarray(img)
        img = torch.from_numpy(img).to(self.device)
        img = img.half()  # åŠç²¾åº¦
        img /= 255.0  # å›¾åƒå½’ä¸€åŒ–
        if img.ndimension() == 3:
            img = img.unsqueeze(0)

        return img0, img

    def detect(self, im):

        im0, img = self.preprocess(im)

        pred = self.m(img, augment=False)[0]
        pred = pred.float()
        pred = non_max_suppression(pred, self.threshold, 0.4)

        pred_boxes = []
        for det in pred:

            if det is not None and len(det):
                det[:, :4] = scale_coords(
                    img.shape[2:], det[:, :4], im0.shape).round()

                for *x, conf, cls_id in det:
                    lbl = self.names[int(cls_id)]
                    if not lbl in ['person', 'car', 'truck']:
                        continue
                    x1, y1 = int(x[0]), int(x[1])
                    x2, y2 = int(x[2]), int(x[3])
                    pred_boxes.append(
                        (x1, y1, x2, y2, lbl, conf))

        return im, pred_boxes
```
- è°ƒç”¨ `self.detect()` æ–¹æ³•è¿”å›å›¾åƒå’Œé¢„æµ‹ç»“æœ
### **DeepSort è¿½è¸ªå™¨**

```python
deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,
                    max_dist=cfg.DEEPSORT.MAX_DIST, min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,
                    nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP, max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,
                    max_age=cfg.DEEPSORT.MAX_AGE, n_init=cfg.DEEPSORT.N_INIT, nn_budget=cfg.DEEPSORT.NN_BUDGET,
                    use_cuda=True)
```
- è°ƒç”¨ `self.update()` æ–¹æ³•æ›´æ–°è¿½è¸ªç»“æœ
---

## **ğŸ“Š è®­ç»ƒè‡ªå·±çš„æ¨¡å‹**

å¦‚æœéœ€è¦è®­ç»ƒè‡ªå®šä¹‰çš„ YOLOv5 æ¨¡å‹ï¼Œè¯·å‚è€ƒä»¥ä¸‹æ•™ç¨‹ï¼š  
[ã€å°ç™½CVã€‘æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨YOLOv5è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼ˆä»Windowsç¯å¢ƒé…ç½®åˆ°æ¨¡å‹éƒ¨ç½²ï¼‰](https://blog.csdn.net/weixin_44936889/article/details/110661862)

è®­ç»ƒå®Œæˆåï¼Œå°†æ¨¡å‹æƒé‡æ–‡ä»¶æ”¾ç½®äº `weights` æ–‡ä»¶å¤¹ä¸­ã€‚

---

## **ğŸ“¦ API è°ƒç”¨**

### **åˆå§‹åŒ–æ£€æµ‹å™¨**
```python
from AIDetector_pytorch import Detector

det = Detector()
```

### **è°ƒç”¨æ£€æµ‹æ¥å£**
```python
func_status = {}
func_status['headpose'] = None

result = det.feedCap(im, func_status)
```

- `im`: è¾“å…¥çš„ BGR å›¾åƒã€‚
- `result['frame']`: æ£€æµ‹ç»“æœçš„å¯è§†åŒ–å›¾åƒã€‚

---

## **âœ¨ å¯è§†åŒ–æ•ˆæœ**

![æ•ˆæœå›¾](https://img-blog.csdnimg.cn/20201231090541223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkzNjg4OQ==,size_16,color_FFFFFF,t_70)

---

## **ğŸ“š è”ç³»ä½œè€…** 
  - Bilibili: [https://space.bilibili.com/470550823](https://space.bilibili.com/470550823)  
  - CSDN: [https://blog.csdn.net/weixin_44936889](https://blog.csdn.net/weixin_44936889)  
  - AI Studio: [https://aistudio.baidu.com/aistudio/personalcenter/thirdview/67156](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/67156)  
  - GitHub: [https://github.com/Sharpiless](https://github.com/Sharpiless)  

---

## **ğŸ‰ å…³æ³¨æˆ‘**

å…³æ³¨æˆ‘çš„å¾®ä¿¡å…¬ä¼—å·ï¼Œè·å–æ›´å¤šæ·±åº¦å­¦ä¹ æ•™ç¨‹ï¼š  
**å…¬ä¼—å·ï¼šå¯è¾¾é¸­çš„æ·±åº¦å­¦ä¹ æ•™ç¨‹**  
![å¾®ä¿¡å…¬ä¼—å·äºŒç»´ç ](https://img-blog.csdnimg.cn/20210127153004430.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkzNjg4OQ==,size_16,color_FFFFFF,t_70)

---

## **ğŸ’¡ è®¸å¯è¯**

æœ¬é¡¹ç›®éµå¾ª **GNU General Public License v3.0** åè®®ã€‚  
**æ ‡æ˜ç›®æ ‡æ£€æµ‹éƒ¨åˆ†æ¥æº**ï¼š[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)
